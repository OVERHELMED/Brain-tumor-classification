"""
Step 5: Explainability with Grad-CAM for MobileNetV2-based Brain MRI Classifier

This script generates Grad-CAM heatmaps to visualize which regions of brain MRI
images the model focuses on when making predictions, and quantifies explanation
faithfulness using deletion/insertion metrics.
"""

import os
import json
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import timm
import cv2
from tqdm import tqdm

# Import Grad-CAM modules
from pytorch_grad_cam import GradCAM, GradCAMPlusPlus
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image
from pytorch_grad_cam.metrics.road import ROADMostRelevantFirst, ROADLeastRelevantFirst


class MobilenetV2WithClassifier(nn.Module):
    """
    Wrapper class that combines MobileNetV2 feature extractor with trained classifier.
    """
    
    def __init__(self, mobilenetv2_model, classifier):
        super().__init__()
        self.mobilenetv2 = mobilenetv2_model
        self.classifier = classifier
        self.scaler = None
        
    def set_scaler(self, scaler):
        """Set the scaler for feature normalization."""
        self.scaler = scaler
        
    def forward(self, x):
        # Extract features using MobileNetV2
        features = self.mobilenetv2(x)
        
        # Normalize features if scaler is available
        if self.scaler is not None:
            features_np = features.detach().cpu().numpy()
            features_scaled = torch.from_numpy(
                self.scaler.transform(features_np)
            ).to(features.device)
        else:
            features_scaled = features
            
        # Apply classifier
        logits = self.classifier(torch.from_numpy(
            self.classifier.predict_proba(features_scaled.detach().cpu().numpy())
        ).to(features.device))
        
        return logits


class BrainMRIExplainabilityAnalyzer:
    """
    Analyzer for brain MRI model explainability using Grad-CAM.
    """
    
    def __init__(self, features_dir, labels_path, model_path=None):
        """
        Initialize the analyzer.
        
        Args:
            features_dir: Directory containing feature files
            labels_path: Path to labels.json
            model_path: Path to saved model (optional)
        """
        self.features_dir = features_dir
        self.labels_path = labels_path
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # Load labels info
        with open(labels_path, 'r') as f:
            self.labels_info = json.load(f)
        
        self.class_names = self.labels_info['class_names']
        self.class_to_idx = self.labels_info['class_to_label']
        
        print(f"Classes: {self.class_names}")
        print(f"Device: {self.device}")
        
        # Setup model
        self._setup_model()
        
        # Setup image preprocessing
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
    def _setup_model(self):
        """Setup the MobileNetV2 + Classifier model."""
        print("Setting up MobileNetV2 + Classifier model...")
        
        # Load features and labels
        X_train = np.load(os.path.join(self.features_dir, "train_X.npy"))
        y_train = np.load(os.path.join(self.features_dir, "train_y.npy"))
        X_val = np.load(os.path.join(self.features_dir, "val_X.npy"))
        y_val = np.load(os.path.join(self.features_dir, "val_y.npy"))
        X_test = np.load(os.path.join(self.features_dir, "test_X.npy"))
        y_test = np.load(os.path.join(self.features_dir, "test_y.npy"))
        
        # Standardize features (same as training)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        X_test_scaled = scaler.transform(X_test)
        
        # Train Logistic Regression classifier
        self.classifier = LogisticRegression(
            multi_class='multinomial',
            solver='lbfgs',
            class_weight='balanced',
            random_state=42,
            C=10,
            max_iter=2000
        )
        
        # Fit on combined train+val
        X_train_val = np.vstack([X_train_scaled, X_val_scaled])
        y_train_val = np.concatenate([y_train, y_val])
        self.classifier.fit(X_train_val, y_train_val)
        
        # Create MobileNetV2 model
        self.mobilenetv2 = timm.create_model(
            'mobilenetv2_100',
            pretrained=True,
            num_classes=0,  # No classifier
            global_pool='avg'
        )
        self.mobilenetv2.eval()
        
        # Store scaler
        self.scaler = scaler
        
        # Store test data for analysis
        self.X_test = X_test
        self.y_test = y_test
        self.test_predictions = self.classifier.predict(X_test_scaled)
        self.test_probabilities = self.classifier.predict_proba(X_test_scaled)
        
        print(f"Model setup complete. Test accuracy: {self.classifier.score(X_test_scaled, y_test):.4f}")
        
    def select_sample_images(self, n_correct=10, n_incorrect=5):
        """
        Select sample images for explainability analysis.
        
        Args:
            n_correct: Number of correctly classified images per class
            n_incorrect: Number of incorrectly classified images per class
            
        Returns:
            Dictionary with selected image indices
        """
        print(f"Selecting {n_correct} correct + {n_incorrect} incorrect samples per class...")
        
        sample_indices = {}
        
        for class_idx, class_name in enumerate(self.class_names):
            # Get indices for this class
            class_mask = self.y_test == class_idx
            class_indices = np.where(class_mask)[0]
            
            # Separate correct and incorrect predictions
            correct_mask = self.test_predictions[class_indices] == class_idx
            correct_indices = class_indices[correct_mask]
            incorrect_indices = class_indices[~correct_mask]
            
            # Select samples
            selected_correct = np.random.choice(
                correct_indices, 
                size=min(n_correct, len(correct_indices)), 
                replace=False
            )
            
            selected_incorrect = np.random.choice(
                incorrect_indices, 
                size=min(n_incorrect, len(incorrect_indices)), 
                replace=False
            )
            
            sample_indices[class_name] = {
                'correct': selected_correct,
                'incorrect': selected_incorrect
            }
            
            print(f"  {class_name}: {len(selected_correct)} correct, {len(selected_incorrect)} incorrect")
        
        return sample_indices
    
    def load_image_from_csv(self, csv_path, image_index):
        """
        Load an image using the path from CSV file.
        
        Args:
            csv_path: Path to CSV file
            image_index: Index of image in the CSV
            
        Returns:
            PIL Image object
        """
        df = pd.read_csv(csv_path)
        image_path = df.iloc[image_index]['path']
        
        # Load and convert to RGB
        image = Image.open(image_path).convert('RGB')
        return image
    
    def generate_gradcam_heatmap(self, image, target_class_idx, method='gradcam'):
        """
        Generate Grad-CAM heatmap for an image.
        
        Args:
            image: PIL Image object
            target_class_idx: Target class index
            method: 'gradcam' or 'gradcam++'
            
        Returns:
            Heatmap overlay image
        """
        # Preprocess image
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # Create wrapper model for Grad-CAM
        class ModelWrapper(nn.Module):
            def __init__(self, mobilenetv2):
                super().__init__()
                self.mobilenetv2 = mobilenetv2
                
            def forward(self, x):
                return self.mobilenetv2(x)
        
        wrapper_model = ModelWrapper(self.mobilenetv2).to(self.device)
        wrapper_model.eval()
        
        # Setup Grad-CAM
        target_layers = [wrapper_model.mobilenetv2.conv_head]  # Last conv layer
        
        if method == 'gradcam':
            cam = GradCAM(model=wrapper_model, target_layers=target_layers)
        else:
            cam = GradCAMPlusPlus(model=wrapper_model, target_layers=target_layers)
        
        # Generate CAM
        targets = [ClassifierOutputTarget(target_class_idx)]
        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)
        
        # Convert image for overlay
        rgb_img = np.array(image)
        rgb_img = cv2.resize(rgb_img, (224, 224))
        rgb_img = rgb_img.astype(np.float32) / 255.0
        
        # Create overlay
        cam_image = show_cam_on_image(rgb_img, grayscale_cam[0], use_rgb=True)
        
        return cam_image, grayscale_cam[0]
    
    def save_heatmap_comparison(self, original_image, heatmap, save_path, 
                               class_name, prediction, confidence, is_correct):
        """
        Save side-by-side comparison of original image and heatmap.
        
        Args:
            original_image: Original PIL image
            heatmap: Heatmap overlay
            save_path: Path to save the comparison
            class_name: Name of the class
            prediction: Model prediction
            confidence: Prediction confidence
            is_correct: Whether prediction is correct
        """
        fig, axes = plt.subplots(1, 2, figsize=(12, 6))
        
        # Original image
        axes[0].imshow(original_image)
        axes[0].set_title(f'Original Image\nTrue: {class_name}', fontsize=12)
        axes[0].axis('off')
        
        # Heatmap
        axes[1].imshow(heatmap)
        prediction_text = f'Pred: {self.class_names[prediction]} ({confidence:.3f})'
        correctness = '‚úì' if is_correct else '‚úó'
        axes[1].set_title(f'Grad-CAM Heatmap\n{prediction_text} {correctness}', fontsize=12)
        axes[1].axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
    
    def analyze_sample_images(self, sample_indices, csv_path):
        """
        Analyze selected sample images and generate heatmaps.
        
        Args:
            sample_indices: Dictionary with selected image indices
            csv_path: Path to test CSV file
        """
        print("Generating Grad-CAM heatmaps for selected images...")
        
        # Create output directory
        output_dir = 'figs/xai/mobilenetv2'
        os.makedirs(output_dir, exist_ok=True)
        
        results = {}
        
        for class_name, indices in sample_indices.items():
            class_dir = os.path.join(output_dir, class_name.lower())
            os.makedirs(class_dir, exist_ok=True)
            
            results[class_name] = {'correct': [], 'incorrect': []}
            
            # Process correct predictions
            for i, img_idx in enumerate(indices['correct']):
                try:
                    # Load image
                    image = self.load_image_from_csv(csv_path, img_idx)
                    
                    # Get prediction info
                    prediction = self.test_predictions[img_idx]
                    confidence = self.test_probabilities[img_idx, prediction]
                    is_correct = prediction == self.y_test[img_idx]
                    
                    # Generate heatmap
                    heatmap, grayscale_cam = self.generate_gradcam_heatmap(
                        image, prediction, method='gradcam'
                    )
                    
                    # Save comparison
                    filename = f"correct_{i:02d}_idx{img_idx}_cam.png"
                    save_path = os.path.join(class_dir, filename)
                    self.save_heatmap_comparison(
                        image, heatmap, save_path, class_name, 
                        prediction, confidence, is_correct
                    )
                    
                    results[class_name]['correct'].append({
                        'image_index': img_idx,
                        'prediction': prediction,
                        'confidence': confidence,
                        'heatmap_path': save_path
                    })
                    
                except Exception as e:
                    print(f"Error processing correct image {img_idx} for {class_name}: {e}")
            
            # Process incorrect predictions
            for i, img_idx in enumerate(indices['incorrect']):
                try:
                    # Load image
                    image = self.load_image_from_csv(csv_path, img_idx)
                    
                    # Get prediction info
                    prediction = self.test_predictions[img_idx]
                    confidence = self.test_probabilities[img_idx, prediction]
                    is_correct = prediction == self.y_test[img_idx]
                    
                    # Generate heatmap
                    heatmap, grayscale_cam = self.generate_gradcam_heatmap(
                        image, prediction, method='gradcam'
                    )
                    
                    # Save comparison
                    filename = f"incorrect_{i:02d}_idx{img_idx}_cam.png"
                    save_path = os.path.join(class_dir, filename)
                    self.save_heatmap_comparison(
                        image, heatmap, save_path, class_name, 
                        prediction, confidence, is_correct
                    )
                    
                    results[class_name]['incorrect'].append({
                        'image_index': img_idx,
                        'prediction': prediction,
                        'confidence': confidence,
                        'heatmap_path': save_path
                    })
                    
                except Exception as e:
                    print(f"Error processing incorrect image {img_idx} for {class_name}: {e}")
        
        return results
    
    def calculate_faithfulness_metrics(self, sample_indices, csv_path):
        """
        Calculate faithfulness metrics using deletion/insertion.
        
        Args:
            sample_indices: Dictionary with selected image indices
            csv_path: Path to test CSV file
            
        Returns:
            Dictionary with faithfulness metrics
        """
        print("Calculating faithfulness metrics...")
        
        faithfulness_results = {}
        
        for class_name, indices in sample_indices.items():
            class_results = {'correct': [], 'incorrect': []}
            
            # Process a few samples for faithfulness (computationally expensive)
            n_samples = min(3, len(indices['correct']))
            selected_correct = np.random.choice(indices['correct'], n_samples, replace=False)
            
            for img_idx in selected_correct:
                try:
                    # Load image
                    image = self.load_image_from_csv(csv_path, img_idx)
                    
                    # Get original prediction
                    original_prediction = self.test_predictions[img_idx]
                    original_confidence = self.test_probabilities[img_idx, original_prediction]
                    
                    # Simple faithfulness metric: perturbation analysis
                    # This is a simplified version - in practice, you'd use more sophisticated metrics
                    
                    # Resize image and convert to tensor
                    input_tensor = self.transform(image).unsqueeze(0).to(self.device)
                    
                    # Get feature representation
                    with torch.no_grad():
                        features = self.mobilenetv2(input_tensor)
                        features_scaled = torch.from_numpy(
                            self.scaler.transform(features.cpu().numpy())
                        )
                        prob = torch.softmax(
                            torch.from_numpy(self.classifier.predict_proba(features_scaled.numpy())),
                            dim=1
                        )
                        original_prob = prob[0, original_prediction].item()
                    
                    # Simple perturbation: add noise and measure probability change
                    noise_levels = [0.1, 0.2, 0.3, 0.4, 0.5]
                    prob_changes = []
                    
                    for noise_level in noise_levels:
                        noisy_tensor = input_tensor + torch.randn_like(input_tensor) * noise_level
                        
                        with torch.no_grad():
                            noisy_features = self.mobilenetv2(noisy_tensor)
                            noisy_features_scaled = torch.from_numpy(
                                self.scaler.transform(noisy_features.cpu().numpy())
                            )
                            noisy_prob = torch.softmax(
                                torch.from_numpy(self.classifier.predict_proba(noisy_features_scaled.numpy())),
                                dim=1
                            )
                            noisy_prob_val = noisy_prob[0, original_prediction].item()
                        
                        prob_change = abs(original_prob - noisy_prob_val)
                        prob_changes.append(prob_change)
                    
                    # Calculate robustness score (lower change = more robust)
                    robustness_score = 1.0 - np.mean(prob_changes)
                    
                    class_results['correct'].append({
                        'image_index': img_idx,
                        'original_confidence': original_confidence,
                        'robustness_score': robustness_score,
                        'prob_changes': prob_changes
                    })
                    
                except Exception as e:
                    print(f"Error calculating faithfulness for image {img_idx}: {e}")
            
            faithfulness_results[class_name] = class_results
        
        return faithfulness_results


def main():
    """Main function for Step 5: Explainability Analysis."""
    print("=== Step 5: Explainability with Grad-CAM ===\n")
    
    # Setup paths
    features_dir = "data/brainmri_4c/features/mobilenetv2"
    labels_path = "data/brainmri_4c/labels.json"
    test_csv_path = "data/brainmri_4c/test.csv"
    
    # Initialize analyzer
    analyzer = BrainMRIExplainabilityAnalyzer(features_dir, labels_path)
    
    # Select sample images
    sample_indices = analyzer.select_sample_images(n_correct=10, n_incorrect=5)
    
    # Generate heatmaps
    heatmap_results = analyzer.analyze_sample_images(sample_indices, test_csv_path)
    
    # Calculate faithfulness metrics
    faithfulness_results = analyzer.calculate_faithfulness_metrics(sample_indices, test_csv_path)
    
    # Save results
    print("\n--- Saving Explainability Results ---")
    os.makedirs('experiments/results', exist_ok=True)
    
    # Prepare results summary
    results_summary = {
        'heatmap_analysis': {
            'total_images_analyzed': sum(
                len(indices['correct']) + len(indices['incorrect']) 
                for indices in sample_indices.values()
            ),
            'images_per_class': {
                class_name: {
                    'correct': len(indices['correct']),
                    'incorrect': len(indices['incorrect'])
                }
                for class_name, indices in sample_indices.items()
            }
        },
        'faithfulness_metrics': {
            class_name: {
                'average_robustness': np.mean([
                    result['robustness_score'] 
                    for result in results['correct']
                ]) if results['correct'] else 0.0,
                'n_samples_analyzed': len(results['correct'])
            }
            for class_name, results in faithfulness_results.items()
        },
        'output_directories': {
            'heatmaps_base_dir': 'figs/xai/mobilenetv2/',
            'class_directories': [
                f'figs/xai/mobilenetv2/{class_name.lower()}/'
                for class_name in analyzer.class_names
            ]
        },
        'method_details': {
            'gradcam_method': 'Grad-CAM',
            'target_layer': 'MobileNetV2 conv_head (last convolutional layer)',
            'faithfulness_metric': 'Perturbation-based robustness score',
            'image_preprocessing': '224x224 resize, ImageNet normalization'
        }
    }
    
    with open('experiments/results/explainability_results.json', 'w') as f:
        json.dump(results_summary, f, indent=2, default=str)
    
    print(f"Explainability results saved to: experiments/results/explainability_results.json")
    
    # Print summary
    print(f"\n=== Step 5 Complete: Explainability Analysis ===")
    print(f"‚úÖ Generated Grad-CAM heatmaps for {results_summary['heatmap_analysis']['total_images_analyzed']} images")
    print(f"‚úÖ Heatmaps saved to figs/xai/mobilenetv2/")
    print(f"‚úÖ Faithfulness metrics calculated")
    print(f"‚úÖ Results saved to experiments/results/")
    
    # Print example file paths for paper
    print(f"\nüìÅ Example heatmap files for paper:")
    for class_name in analyzer.class_names:
        class_dir = f'figs/xai/mobilenetv2/{class_name.lower()}/'
        if os.path.exists(class_dir):
            files = os.listdir(class_dir)
            if files:
                print(f"  {class_name}: {class_dir}{files[0]}")
    
    print(f"\nüéâ Ready for Step 6: External validation or model comparison!")


if __name__ == "__main__":
    main()
